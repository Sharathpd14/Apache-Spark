# Spark SQL Queries: Writing Efficient and Scalable Queries

Spark SQL allows you to interact with structured data using SQL queries while benefiting from Sparkâ€™s parallel processing capabilities. In this blog, weâ€™ll cover Spark SQL queries, from basic selections to advanced optimizations.

## ðŸ› ï¸ Setting Up Spark SQL

Before writing queries, letâ€™s create a SparkSession (the entry point for Spark SQL).

```python
from pyspark.sql import SparkSession

# Create a Spark session
spark = SparkSession.builder.appName("SparkSQLQueries").getOrCreate()
```


## ðŸ” Querying Data Using Spark SQL

### Loading Data into Spark SQL

We need data to query! Letâ€™s load a JSON file and create a temporary SQL table.

```python
df = spark.read.json("employees.json")

# Register as a temporary SQL table
df.createOrReplaceTempView("employees")
```

## ðŸ“Œ Basic SQL Queries in Spark SQL

### âœ… Selecting Data

### SQL:
```sql
SELECT * FROM employees;
```

ðŸ’¡ **Python Equivalent:**
```python
spark.sql("SELECT * FROM employees").show()
```
### âœ… Filtering Data (WHERE Clause)

### SQL:
```sql
SELECT name, salary FROM employees WHERE salary > 50000;
```

ðŸ’¡ **Python Equivalent:**
```python
spark.sql("SELECT name, salary FROM employees WHERE salary > 50000").show()
```
### âœ… Sorting Data (ORDER BY)

### SQL:
```sql
SELECT name, salary FROM employees ORDER BY salary DESC;
```

ðŸ’¡ **Python Equivalent:**
```python
spark.sql("SELECT name, salary FROM employees ORDER BY salary DESC").show()
```
### âœ… Limiting Results

### SQL:
```sql
SELECT * FROM employees LIMIT 5;
```

ðŸ’¡ **Python Equivalent:**
```python
spark.sql("SELECT * FROM employees LIMIT 5").show()
```
### ðŸ“Œ Aggregations & Grouping

### âœ… Counting Rows

#### SQL:
```sql
SELECT COUNT(*) FROM employees;
```

ðŸ’¡ **Python Equivalent:**
```python
spark.sql("SELECT COUNT(*) FROM employees").show()
```
### âœ… Grouping Data (GROUP BY)

#### SQL:
```sql
SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department;
```

ðŸ’¡ **Python Equivalent:**
```python
spark.sql("SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department").show()
```
